Uma vez que um tamanho de bloco tenha sido escolhido, a próxima questão é como monitorar os blocos livres. Dois métodos são amplamente usados, como mostrado na Figura 4.22. O primeiro consiste em usar uma lista encadeada de blocos de disco, com cada bloco contendo tantos números de blocos livres de disco quantos couberem nele. Com um bloco de 1 KB e um número de bloco de disco de 32 bits, cada bloco na lista livre contém os números de 255 blocos livres. (Uma entrada é reservada para o ponteiro para o bloco seguinte.) Considere um disco de 1 TB, que tem em torno de 1 bilhão de blocos de disco. Armazenar todos esses endereços em blocos de 255 exige cerca de 4 milhões de blocos. Em geral, blocos livres são usados para conter a lista livre, de maneira que o armazenamento seja essencialmente gratuito. A outra técnica de gerenciamento de espaço livre é o mapa de bits. Um disco com n blocos exige um mapa de bits com n bits. Blocos livres são representados por 1s no mapa, blocos alocados por 0s (ou vice-versa). Para nosso disco de 1 TB de exemplo, precisamos de 1 bilhão de bits para o mapa, o que exige em torno de 130.000 blocos de 1 KB para armazenar. Não surpreende que o mapa de bits exija menos espaço, tendo em vista que ele usa 1 bit por bloco, versus 32 bits no modelo de lista encadeada. Apenas se o disco estiver praticamente cheio (isto é, tiver poucos blocos livres) o esquema da lista encadeada exigirá menos blocos do que o mapa de bits.Se os blocos livres tenderem a vir em longos conjuntos de blocos consecutivos, o sistema da lista de blocos livres pode ser modificado para controlar conjuntos de blocos em vez de blocos individuais. Um contador de 8, 16 ou 32 bits poderia ser associado com cada bloco dando o número de blocos livres consecutivos. No melhor caso, um disco basicamente vazio seria representado por dois números: o endereço do primeiro bloco livre seguido pelo contador de blocos livres. Por outro lado, se o disco se tornar severamente fragmentado, o controle de conjuntos de blocos será menos eficiente do que o controle de blocos individuais, pois não apenas o endereço deverá ser armazenado, mas também o contador. Essa questão ilustra um problema que os projetistas de sistemas operacionais muitas vezes enfrentam. Existem múltiplas estruturas de dados e algoritmos que podem ser usados para solucionar um problema, mas a escolha do melhor exige dados que os projetistas não têm e não terão até que o sistema seja distribuído e amplamente utilizado. E, mesmo assim, os dados podem não estar disponíveis. Por exemplo, nossas próprias medidas de tamanhos de arquivos na Universidade de Vrije em 1984 e 1995, os dados do site e os dados de Cornell são apenas quatro amostras. Embora muito melhor do que nada, temos pouca certeza se eles são também representativos de computadores pessoais, computadores corporativos, computadores do governo e outros. Com algum esforço poderíamos ser capazes de conseguir algumasamostras de outros tipos de computadores, masmesmo assim seria uma bobagem extrapolar para todos os computadores dos tipos mensurados. Voltando para o método da lista de blocos livres por um momento, apenas um bloco de ponteiros precisa ser mantido na memória principal. Quando um arquivo é criado, os blocos necessários são tomados do bloco de ponteiros. Quando ele se esgota, um novo bloco de ponteiros é lido do disco. De modo similar, quando um arquivo é removido, seus blocos são liberados e adicionados ao bloco de ponteiros na memória principal. Quando esse bloco completa, ele é escrito no disco. Em determinadas circunstâncias, esse método leva a operações desnecessárias de E/S em disco. Considere a situação da Figura 4.23(a), na qual o bloco de ponteiros 
na memória tem espaço para somente duas entradas. Se 
um arquivo de três blocos for liberado, o bloco de ponteiros transbordará e ele deverá ser escrito para o disco, 
levando à situação da Figura 4.23(b). Se um arquivo de 
três blocos for escrito agora, o bloco de ponteiros cheio 
deverá ser lido novamente, trazendo-nos de volta para 
a Figura 4.23(a). Se o arquivo de três blocos recém-
-escrito constituir um arquivo temporário, quando ele 
for liberado, será necessária outra operação de escrita 
para escrever novamente o bloco de ponteiros cheio no 
disco. Resumindo, quando o bloco de ponteiros estiver 
quase vazio, uma série de arquivos temporários de vida 
curta pode causar muitas operações de E/S em disco. 
Uma abordagem alternativa que evita a maior parte dessas operações de E/S em disco é dividir o bloco cheio de ponteiros. Desse modo, em vez de ir da Figura 
4.23(a) para a Figura 4.23(b), vamos da Figura 4.23(a) 
para a Figura 4.23(c) quando três blocos são liberados. 
Agora o sistema pode lidar com uma série de arquivos 
temporários sem realizar qualquer operação de E/S em 
disco. Se o bloco na memória encher, ele será escrito 
para o disco e o bloco meio cheio será lido do disco. A 
ideia aqui é manter a maior parte dos blocos de ponteiros cheios em disco (para minimizar o uso deste), mas 
manter o bloco na memória cheio pela metade, de maneira que ele possa lidar tanto com a criação quanto com 
a remoção de arquivos, sem uma operação de E/S em 
disco para a lista de livres. 
Com um mapa de bits, também é possível manter 
apenas um bloco na memória, usando o disco para outro 
bloco apenas quando ele ficar completamente cheio ou 
vazio. Um benefício adicional dessa abordagem é que 
ao realizar toda a alocação de um único bloco do mapa 
de bits, os blocos de disco estarão mais próximos, minimizando assim os movimentos do braço do disco. Já 
que o mapa de bits é uma estrutura de dados de tamanho fixo, se o núcleo estiver (parcialmente) paginado, o 
mapa de bits pode ser colocado na memória virtual e ter 
suas páginas paginadas conforme a necessidade.
Para evitar que as pessoas exagerem no uso do espaço de disco, sistemas operacionais de múltiplos usuários 
muitas vezes fornecem um mecanismo para impor cotas de disco. A ideia é que o administrador do sistema 
designe a cada usuário uma cota máxima de arquivos e 
blocos, e o sistema operacional se certifique de que os 
usuários não excedam essa cota. Um mecanismo típico 
é descrito a seguir. 
Quando um usuário abre um arquivo, os atributos e 
endereços de disco são localizados e colocados em umatabela de arquivos aberta na memória principal. Entre 
os atributos há uma entrada dizendo quem é o proprietário. Quaisquer aumentos no tamanho do arquivo serão 
cobrados da cota do proprietário. 
Uma segunda tabela contém os registros de cotas de 
todos os usuários com um arquivo aberto, mesmo que esse 
arquivo tenha sido aberto por outra pessoa. Essa tabela está 
mostrada na Figura 4.24. Ela foi extraída de um arquivo de 
cotas no disco para os usuários cujos arquivos estão atualmente abertos. Quando todos os arquivos são fechados, o 
registro é escrito de volta para o arquivo de cotas. 
Quando uma nova entrada é feita na tabela de arquivos abertos, um ponteiro para o registro de cota do proprietário é atribuído a ela, a fim de facilitar encontrar os 
vários limites. Toda vez que um bloco é adicionado a um 
arquivo, o número total de blocos cobrados do proprietário é incrementado, e os limites flexíveis e estritos são 
verificados. O limite flexível pode ser excedido, mas o 
limite estrito não. Uma tentativa de adicionar blocos a 
um arquivo quando o limite de blocos estrito tiver sido 
alcançado resultará em um erro. Verificações análogas 
também existem para o número de arquivos a fim de evitar que algum usuário sobrecarregue todos os i-nodes. 
Quando um usuário tenta entrar no sistema, este 
examina o arquivo de cotas para ver se ele excedeu o 
limite flexível para o número de arquivos ou o número de blocos de disco. Se qualquer um dos limites foi 
violado, um aviso é exibido, e o contador de avisos restantes é reduzido para um. Se o contador chegar a zero, 
o usuário ignorou o aviso vezes demais, e não tem permissão para entrar. Conseguir a autorização para entrar 
novamente exigirá alguma conversa com o administrador do sistema. 
Esse método tem a propriedade de que os usuários podem ir além de seus limites flexíveis durante uma sessão 
de uso, desde que removam o excesso antes de se desconectarem. Os limites estritos jamais podem ser excedidos.
A destruição de um sistema de arquivos é quase sempre um desastre muito maior do que a destruição de um 
computador. Se um computador for destruído pelo fogo, 
por uma descarga elétrica ou uma xícara de café derrubada no teclado, isso é irritante e custará dinheiro, mas 
geralmente uma máquina nova pode ser comprada com 
um mínimo de incômodo. Computadores pessoais baratos podem ser substituídos na mesma hora, bastando 
uma ida à loja (menos nas universidades, onde emitir 
uma ordem de compra exige três comitês, cinco assinaturas e 90 dias). 
Se o sistema de arquivos de um computador estiver irrevogavelmente perdido, seja pelo hardware ou 
pelo software, restaurar todas as informações será difícil, exigirá tempo e, em muitos casos, será impossível. 
Para as pessoas cujos programas, documentos, registros 
tributários, arquivos de clientes, bancos de dados, planos de marketing, ou outros dados estiverem perdidos 
para sempre as consequências podem ser catastróficas. 
Apesar de o sistema de arquivos não conseguir oferecer 
qualquer proteção contra a destruição física dos equipamentos e da mídia, ele pode ajudar a proteger as informações. A solução é bastante clara: fazer cópias de 
segurança (backups). Mas isso pode não ser tão simples 
quanto parece. Vamos examinar a questão. 
A maioria das pessoas não acredita que fazer backups 
dos seus arquivos valha o tempo e o esforço — até que um belo dia seu disco morre abruptamente, momento 
que a maioria delas jamais esquecerá. As empresas, no 
entanto, compreendem (normalmente) bem o valor dos 
seus dados e costumam realizar um backup ao menos 
uma vez ao dia, muitas vezes em fita. As fitas modernas 
armazenam centenas de gigabytes e custam centavos 
por gigabyte. Não obstante isso, realizar backups não é 
algo tão trivial quanto parece, então examinaremos algumas das questões relacionadas a seguir. 
Backups para fita são geralmente feitos para lidar 
com um de dois problemas potenciais: 
1. Recuperação em caso de um desastre. 
2. Recuperação de uma bobagem feita. 
O primeiro problema diz respeito a fazer o computador funcionar novamente após uma quebra de disco, 
fogo, enchente ou outra catástrofe natural. Na prática, 
essas coisas não acontecem com muita frequência, razão pela qual muitas pessoas não se preocupam em fazer backups. Essas pessoas também tendem a não ter 
seguro contra incêndio em suas casas pela mesma razão. 
A segunda razão é que os usuários muitas vezes 
removem acidentalmente arquivos de que precisam 
mais tarde outra vez. Esse problema ocorre com tanta 
frequência que, quando um arquivo é “removido” no 
Windows, ele não é apagado de maneira alguma, mas 
simplesmente movido para um diretório especial, a cesta de reciclagem, de maneira que ele possa buscado e 
restaurado facilmente mais tarde. Backups levam esse 
princípio mais longe ainda e permitem que arquivos que foram removidos há dias, mesmo semanas, sejam restaurados de velhas fitas de backup. 
Fazer backup leva um longo tempo e ocupa um 
espaço significativo, portanto é importante fazê-lo de 
maneira eficiente e conveniente. Essas considerações 
levantam as questões a seguir. Primeiro, será que todo 
o sistema de arquivos deve ser copiado ou apenas parte 
dele? Em muitas instalações, os programas executáveis 
(binários) são mantidos em uma parte limitada da árvore do sistema de arquivos. Não é necessário realizar 
backup de todos esses arquivos se todos eles podem 
ser reinstalados a partir do site do fabricante ou de um 
DVD de instalação. Também, a maioria dos sistemas 
tem um diretório para arquivos temporários. Em geral 
não há uma razão para fazer um backup dele também. 
No UNIX, todos os arquivos especiais (dispositivos 
de E/S) são mantidos em um diretório /dev. Fazer um 
backup desse diretório não só é desnecessário, como é 
realmente perigoso, pois o programa de backup poderia 
ficar pendurado para sempre se ele tentasse ler cada um 
desses arquivos até terminar. Resumindo, normalmente 
é desejável fazer o backup apenas de diretórios específicos e tudo neles em vez de todo o sistema de arquivos. 
Segundo, é um desperdício fazer o backup de arquivos que não mudaram desde o último backup, o que 
leva à ideia de cópias incrementais. A forma mais simples de cópia incremental é realizar uma cópia (backup) 
completa periodicamente, digamos por semana ou por 
mês, e realizar uma cópia diária somente daqueles arquivos que foram modificados desde a última cópia 
completa. Melhor ainda é copiar apenas aqueles arquivos que foram modificados desde a última vez em que 
foram copiados. Embora esse esquema minimize o tempo de cópia, ele torna a recuperação mais complicada, 
pois primeiro a cópia mais recente deve ser restaurada e 
depois todas as cópias incrementais têm de ser restauradas na ordem inversa. Para facilitar a recuperação, muitas vezes são usados esquemas de cópias incrementais 
mais sofisticados. 
Terceiro, visto que quantidades imensas de dados 
geralmente são copiadas, pode ser desejável comprimir 
os dados antes de escrevê-los na fita. No entanto, com 
muitos algoritmos de compressão, um único defeito na 
fita de backup pode estragar o algoritmo e tornar um arquivo inteiro ou mesmo uma fita inteira ilegível. Desse 
modo, a decisão de comprimir os dados de backup deve 
ser cuidadosamente considerada. 
Quarto, é difícil realizar um backup em um sistema de arquivos ativo. Se os arquivos e diretórios estão 
sendo adicionados, removidos e modificados durante o processo de cópia, a cópia resultante pode ficar inconsistente. No entanto, como realizar uma cópia 
pode levar horas, talvez seja necessário deixar o sistema off-line por grande parte da noite para realizar o 
backup, algo que nem sempre é aceitável. Por essa razão, algoritmos foram projetados para gerar fotografias 
(snapshots) rápidas do estado do sistema de arquivos 
copiando estruturas críticas de dados e então exigindo 
que nas mudanças futuras em arquivos e diretórios sejam realizadas cópias dos blocos em vez de atualizá-los 
diretamente (HUTCHINSON et al., 1999). Dessa maneira, o sistema de arquivos é efetivamente congelado 
no momento do snapshot; portanto, pode ser copiado 
depois quando o usuário quiser. 
Quinto e último, fazer backups introduz muitos problemas não técnicos na organização. O melhor sistema 
de segurança on-line no mundo pode ser inútil se o administrador do sistema mantiver todos os discos ou fitas de 
backup em seu gabinete e deixá-lo aberto e desguarnecido sempre que for buscar um café no fim do corredor. 
Tudo o que um espião precisa fazer é aparecer por um 
segundo, colocar um disco ou fita minúsculos em seu 
bolso e cair fora lepidamente. Adeus, segurança. Também, realizar um backup diário tem pouco uso se o fogo 
que queimar os computadores também queimar todos 
os discos de backup. Por essa razão, discos de backup 
devem ser mantidos longe dos computadores, mas isso 
introduz mais riscos (pois agora dois locais precisam 
contar com segurança). Para uma discussão aprofundada dessas e de outras questões administrativas práticas, 
ver Nemeth et al. (2013). A seguir discutiremos apenas 
as questões técnicas envolvidas em realizar backups de 
sistemas de arquivos. 
Duas estratégias podem ser usadas para copiar um 
disco para um disco de backup: uma cópia física ou 
uma cópia lógica. Uma cópia física começa no bloco 
0 do disco, escreve em ordem todos os blocos de disco no disco de saída, e para quando ele tiver copiado 
o último. Esse programa é tão simples que provavelmente pode ser feito 100% livre de erros, algo que em 
geral não pode ser dito a respeito de qualquer outro 
programa útil. 
Mesmo assim, vale a pena fazer vários comentários 
a respeito da cópia física. Por um lado, não faz sentido 
fazer backup de blocos de disco que não estejam sendo 
usados. Se o programa de cópia puder obter acesso à estrutura de dados dos blocos livres, ele pode evitar copiar 
blocos que não estejam sendo usados. No entanto, pular 
blocos que não estejam sendo usados exige escrever o 
número de cada bloco na frente dele (ou o equivalente), 
já que não é mais verdade que o bloco k no backup era 
o bloco k no disco.
Uma segunda preocupação é copiar blocos defeituosos. É quase impossível manufaturar discos grandes sem quaisquer defeitos. Alguns blocos defeituosos 
estão sempre presentes. Às vezes, quando é feita uma 
formatação de baixo nível, os blocos defeituosos são 
detectados, marcados como tal e substituídos por blocos 
de reserva guardados ao final de cada trilha para precisamente esse tipo de emergência. Em muitos casos, o 
controlador de disco gerencia a substituição de blocos 
defeituosos de forma transparente sem que o sistema 
operacional nem fique sabendo a respeito. 
No entanto, às vezes os blocos passam a apresentar defeitos após a formatação, caso em que o sistema 
operacional eventualmente vai detectá-los. Em geral, 
ele soluciona o problema criando um “arquivo” consistindo em todos os blocos defeituosos — somente para 
certificar-se de que eles jamais apareçam como livres e 
sejam ocupados. Desnecessário dizer que esse arquivo 
é completamente ilegível. 
Se todos os blocos defeituosos forem remapeados 
pelo controlador do disco e escondidos do sistema operacional como descrito há pouco, a cópia física funcionará bem. Por outro lado, se eles forem visíveis para o 
sistema operacional e mantidos em um ou mais arquivos de blocos defeituosos ou mapas de bits, é absolutamente essencial que o programa de cópia física tenha 
acesso a essa informação e evite copiá-los para evitar 
erros de leitura de disco intermináveis enquanto tenta 
fazer o backup do arquivo de bloco defeituoso. 
Sistemas Windows têm arquivos de paginação e hibernação que não são necessários no caso de uma restauração e não devem ser copiados em primeiro lugar. 
Sistemas específicos talvez também tenham outros arquivos internos que não devem ser copiados, então o 
programa de backup precisa ter consciência deles. 
As principais vantagens da cópia física são a simplicidade e a grande velocidade (basicamente, ela pode 
ser executada na velocidade do disco). As principais 
desvantagens são a incapacidade de pular diretórios selecionados, realizar cópias incrementais e restaurar arquivos individuais mediante pedido. Por essas razões, a 
maioria das instalações faz cópias lógicas. 
Uma cópia lógica começa em um ou mais diretórios 
especificados e recursivamente copia todos os arquivos 
e diretórios encontrados ali que foram modificados desde uma determinada data de base (por exemplo, o último backup para uma cópia incremental ou instalação 
de sistema para uma cópia completa). Assim, em uma 
cópia lógica, o disco da cópia recebe uma série de diretórios e arquivos cuidadosamente identificados, o que torna fácil restaurar um arquivo ou diretório específico 
mediante pedido. 
Tendo em vista que a cópia lógica é a forma mais 
usual, vamos examinar um algoritmo comum em detalhe usando o exemplo da Figura 4.25 para nos orientar. 
A maioria dos sistemas UNIX usa esse algoritmo. Na 
figura vemos uma árvore com diretórios (quadrados) e 
arquivos (círculos). Os itens sombreados foram modificados desde a data de base e desse modo precisam ser 
copiados. Os arquivos não sombreados não precisam 
ser copiados. 
Esse algoritmo também copia todos os diretórios 
(mesmo os inalterados) que ficam no caminho de um 
arquivo ou diretório modificado por duas razões. A primeira é tornar possível restaurar os arquivos e diretórios copiados para um sistema de arquivos novos em um 
computador diferente. Dessa maneira, os programas de 
cópia e restauração podem ser usados para transportar 
sistemas de arquivos inteiros entre computadores. 
A segunda razão para copiar diretórios inalterados 
que estejam acima de arquivos modificados é tornar 
possível restaurar de maneira incremental um único arquivo (possivelmente para recuperar alguma bobagem 
cometida). Suponha que uma cópia completa do sistema 
de arquivos seja feita no domingo à noite e uma cópia 
incremental seja feita segunda-feira à noite. Na terça-
-feira o diretório /usr/jhs/proj/nr3 é removido, junto 
com todos os diretórios e arquivos sob ele. Na manhã 
ensolarada de quarta-feira suponha que o usuário queira restaurar o arquivo /usr/jhs/proj/nr3/plans/summary. 
No entanto, não é possível apenas restaurar o arquivo 
summary porque não há lugar para colocá-lo. Os diretórios nr3 e plans devem ser restaurados primeiro. Para 
obter seus proprietários, modos, horários etc. corretos, 
esses diretórios precisam estar presentes no disco de cópia mesmo que eles mesmos não tenham sido modificados antes da cópia completa anterior. 
O algoritmo de cópia mantém um mapa de bits indexado pelo número do i-node com vários bits por i-node. 
Bits serão definidos como 1 ou 0 nesse mapa conforme 
o algoritmo é executado. O algoritmo opera em quatro 
fases. A fase 1 começa do diretório inicial (a raiz neste 
exemplo) e examina todas as entradas nele. Para cada 
arquivo modificado, seu i-node é marcado no mapa de 
bits. Cada diretório também é marcado (modificado ou 
não) e então inspecionado recursivamente. 
Ao fim da fase 1, todos os arquivos modificados e 
todos os diretórios foram marcados no mapa de bits, 
como mostrado (pelo sombreamento) na Figura 4.26(a). 
A fase 2 conceitualmente percorre a árvore de novo de 
maneira recursiva, desmarcando quaisquer diretórios que não tenham arquivos ou diretórios modificados neles ou sob eles. Essa fase deixa o mapa de bits como 
mostrado na Figura 4.26(b). Observe que os diretórios 
10, 11, 14, 27, 29 e 30 estão agora desmarcados, pois 
não contêm nada modificado sob eles. Eles não serão 
copiados. Por outro lado, os diretórios 5 e 6 serão copiados mesmo que não tenham sido modificados, pois 
serão necessários para restaurar as mudanças de hoje 
para uma máquina nova. Para fins de eficiência, as fases 1 e 2 podem ser combinadas para percorrer a árvore 
uma única vez. 
Nesse ponto, sabe-se quais diretórios e arquivos 
precisam ser copiados. Esses são os arquivos que estão marcados na Figura 4.26(b). A fase 3 consiste em 
escanear os i-nodes em ordem numérica e copiar todos 
os diretórios que estão marcados para serem copiados. 
Esses são mostrados na Figura 4.26(c). Cada diretório 
é prefixado pelos atributos do diretório (proprietário, 
horários etc.), de maneira que eles possam ser restaurados. Por fim, na fase 4, os arquivos marcados na Figura 
4.26(d) também são copiados, mais uma vez prefixados 
por seus atributos. Isso completa a cópia.
Restaurar um sistema de arquivos a partir do disco 
de cópia é algo simples. Para começar, um sistema de 
arquivos vazio é criado no disco. Então a cópia completa mais recente é restaurada. Já que os diretórios 
aparecem primeiro no disco de cópia, eles são todos 
restaurados antes, fornecendo um esqueleto ao sistema 
de arquivos. Então os arquivos em si são restaurados. 
Esse processo é repetido com a primeira cópia incremental feita após a cópia completa, depois a seguinte e 
assim por diante. 
Embora a cópia lógica seja simples, há algumas questões complicadas. Por exemplo, já que a lista de blocos 
livres não é um arquivo, ele não é copiado e assim deve 
ser reconstruído desde o ponto de partida depois de todas as cópias terem sido restauradas. Realizá-lo sempre 
é possível já que o conjunto de blocos livres é apenas o 
complemento do conjunto dos blocos contidos em todos 
os arquivos combinados. 
Outra questão são as ligações. Se um arquivo está 
ligado a dois ou mais diretórios, é importante que seja 
restaurado apenas uma vez e que todos os diretórios que 
supostamente estejam apontando para ele assim o façam.
Ainda outra questão é o fato de que os arquivos 
UNIX possam conter lacunas. É permitido abrir um arquivo, escrever alguns bytes, então deslocar para uma 
posição mais distante e escrever mais alguns bytes. 
Os blocos entre eles não fazem parte do arquivo e não 
devem ser copiados e restaurados. Arquivos contendo 
a imagem de processos terminados de modo anormal 
(core files) apresentam muitas vezes uma lacuna de 
centenas de megabytes entre os segmentos de dados e 
a pilha. Se não for tratado adequadamente, cada core 
file restaurado preencherá essa área com zeros e desse modo terá o mesmo tamanho do espaço de endereço 
virtual (por exemplo, 232 bytes, ou pior ainda, 264 bytes). 
Por fim, arquivos especiais, chamados pipes, e outros similares (qualquer coisa que não seja um arquivo 
real) jamais devem ser copiados, não importa em qual 
diretório eles possam ocorrer (eles não precisam estar confinados em /dev). Para mais informações sobre 
backups de sistemas de arquivos, ver Chervenak et al. 
(1998) e Zwicky (1991). 
Outra área na qual a confiabilidade é um problema é 
a consistência do sistema de arquivos. Muitos sistemas 
de arquivos leem blocos, modificam-nos e só depois os 
escrevem. Se o sistema cair antes de todos os blocos 
modificados terem sido escritos, o sistema de arquivos 
pode ser deixado em um estado inconsistente. O problema é especialmente crítico se alguns dos blocos que não 
foram escritos forem blocos de i-nodes, de diretórios ou 
blocos contendo a lista de blocos livres. 
Para lidar com sistemas de arquivos inconsistentes, 
a maioria dos programas tem um programa utilitário 
que confere a consistência do sistema de arquivos. Por 
exemplo, UNIX tem fsck; Windows tem sfc (e outros). 
Esse utilitário pode ser executado sempre que o sistema 
é iniciado, especialmente após uma queda. A descrição 
a seguir explica como o fsck funciona. Sfc é de certa 
maneira diferente, pois ele funciona em um sistema de 
arquivos distinto, mas o princípio geral de usar a redundância inerente do sistema de arquivos para repará-lo 
ainda é válido. Todos os verificadores conferem cada 
sistema de arquivos (partição do disco) independentemente dos outros. 
Dois tipos de verificações de consistência podem 
ser feitos: blocos e arquivos. Para conferir a consistência do bloco, o programa constrói duas tabelas, cada 
uma contendo um contador para cada bloco, inicialmente contendo 0. Os contadores na primeira tabela 
monitoram quantas vezes cada bloco está presente em um arquivo; os contadores na segunda tabela registram 
quantas vezes cada bloco está presente na lista de livres 
(ou o mapa de bits de blocos livres). 
O programa então lê todos os i-nodes usando um dispositivo cru, que ignora a estrutura de arquivos e apenas 
retorna todos os blocos de disco começando em 0. A 
partir de um i-node, é possível construir uma lista de todos os números de blocos usados no arquivo correspondente. À medida que cada número de bloco é lido, seu 
contador na primeira tabela é incrementado. O programa então examina a lista de livres ou mapa de bits para 
encontrar todos os blocos que não estão sendo usados. 
Cada ocorrência de um bloco na lista de livres resulta 
em seu contador na segunda tabela sendo incrementado. 
Se o sistema de arquivos for consistente, cada bloco terá um 1 na primeira ou na segunda tabela, como 
ilustrado na Figura 4.27(a). No entanto, como consequência de uma queda no sistema, as tabelas podem 
ser parecidas com a Figura 4.27(b), na qual o bloco 
2 não ocorre em nenhuma tabela. Ele será reportado 
como um bloco desaparecido. Embora blocos desaparecidos não causem nenhum prejuízo real, eles desperdiçam espaço e reduzem assim a capacidade do disco. 
A solução para os blocos desaparecidos é simples: o 
verificador do sistema de arquivos apenas os adiciona 
à lista de blocos livres. 
Outra situação que pode ocorrer é aquela da Figura 
4.27(c). Aqui vemos um bloco, número 4, que ocorre 
duas vezes na lista de livres. (Duplicatas podem ocorrer 
apenas se a lista de livres for realmente uma lista; com 
um mapa de bits isso é impossível.) A solução aqui também é simples: reconstruir a lista de livres. 
A pior coisa que pode ocorrer é o mesmo bloco de 
dados estar presente em dois ou mais arquivos, como 
mostrado na Figura 4.27(d) com o bloco 5. Se qualquer 
um desses arquivos for removido, o bloco 5 será colocado na lista de livres, levando a uma situação na qual 
o mesmo bloco estará ao mesmo tempo em uso e livre. 
Se ambos os arquivos forem removidos, o bloco será 
colocado na lista de livres duas vezes. 
A ação apropriada para o verificador de sistema de 
arquivos é alocar um bloco livre, copiar os conteúdos 
do bloco 5 nele e inserir a cópia em um dos arquivos. 
Dessa maneira, o conteúdo de informação dos arquivos 
ficará inalterado (embora quase certamente adulterado), 
mas a estrutura do sistema de arquivos ao menos ficará 
consistente. O erro deve ser reportado, a fim de permitir 
que o usuário inspecione o dano. 
Além de conferir para ver se cada bloco está contabilizado corretamente, o verificador do sistema de 
arquivos também confere o sistema de diretórios. Ele, também, usa uma tabela de contadores, mas esses são 
por arquivo, em vez de por bloco. Ele começa no diretório-raiz e recursivamente percorre a árvore, inspecionando cada diretório no sistema de arquivos. Para cada 
i-node em cada diretório, ele incrementa um contador 
para contar o uso do arquivo. Lembre-se de que por 
causa de ligações estritas, um arquivo pode aparecer 
em dois ou mais diretórios. Ligações simbólicas não 
contam e não fazem que o contador incremente para o 
arquivo-alvo. 
Quando o verificador tiver concluído, ele terá uma 
lista, indexada pelo número do i-node, dizendo quantos diretórios contém cada arquivo. Ele então compara 
esses números com as contagens de ligações armazenadas nos próprios i-nodes. Essas contagens começam 
em 1 quando um arquivo é criado e são incrementadas 
cada vez que uma ligação (estrita) é feita para o arquivo. Em um sistema de arquivos consistente, ambas as 
contagens concordarão. No entanto, dois tipos de erros 
podem ocorrer: a contagem de ligações no i-node pode 
ser alta demais ou baixa demais. 
Se a contagem de ligações for mais alta do que o número de entradas de diretório, então mesmo que todos 
os arquivos sejam removidos dos diretórios, a contagem 
ainda será diferente de zero e o i-node não será removido. Esse erro não é sério, mas desperdiça espaço no 
disco com arquivos que não estão em diretório algum. 
Ele deve ser reparado atribuindo-se o valor correto à 
contagem de ligações no i-node. 
O outro erro é potencialmente catastrófico. Se duas 
entradas de diretório estão ligadas a um arquivo, mas 
os i-nodes dizem que há apenas uma, quando qualquer 
uma das entradas de diretório for removida, a contagem 
do i-node irá para zero. Quando uma contagem de i-node vai para zero, o sistema de arquivos a marca como inutilizada e libera todos os seus blocos. Essa ação resultará em um dos diretórios agora apontando para um 
i-node não usado, cujos blocos logo podem ser atribuídos a outros arquivos. Outra vez, a solução é apenas 
forçar a contagem de ligações no i-node a assumir o 
número real de entradas de diretório. 
Essas duas operações, conferir os blocos e conferir 
os diretórios, muitas vezes são integradas por razões de 
eficiência (por exemplo, apenas uma verificação nos i-
-nodes é necessária). Outras verificações também são 
possíveis. Por exemplo, diretórios têm um formato definido, com números de i-nodes e nomes em ASCII. Se 
um número de i-node é maior do que o número de i-
-nodes no disco, o diretório foi danificado. 
Além disso, cada i-node tem um modo, alguns dos 
quais são legais, mas estranhos, como o 0007, que 
possibilita ao proprietário e ao seu grupo não terem 
acesso a nada, mas permite que pessoas de fora leiam, 
escrevam e executem o arquivo. Pode ser útil ao menos reportar arquivos que dão aos usuários de fora mais 
direitos do que ao proprietário. Diretórios com mais 
de, digamos, 1.000 entradas também são suspeitos. Arquivos localizados nos diretórios de usuários, mas que 
são de propriedade do superusuário e que tenham o bit 
SETUID em 1, são problemas de segurança potenciais 
porque tais arquivos adquirem os poderes do superusuário quando executados por qualquer usuário. Com um 
pouco de esforço, é possível montar uma lista bastante 
longa de situações tecnicamente legais, mas peculiares, 
que vale a pena relatar. 
Os parágrafos anteriores discutiram o problema de 
proteger o usuário contra quedas no sistema. Alguns sistemas de arquivos também se preocupam em proteger 
o usuário contra si mesmo. Se o usuário quiser digitar 
rm *.o
para remover todos os arquivos terminando com .o (arquivos-objeto gerados pelo compilador), mas acidentalmente digita 
rm * .o
(observe o espaço após o asterisco), rm removerá todos 
os arquivos no diretório atual e então reclamará que não 
pode encontrar .o. No Windows, os arquivos que são 
removidos são colocados na cesta de reciclagem (um 
diretório especial), do qual eles podem ser recuperados 
mais tarde se necessário. É claro, nenhum espaço é liberado até que eles sejam realmente removidos desse 
diretório.
O acesso ao disco é muito mais lento do que o acesso à memória. Ler uma palavra de 32 bits de memória 
pode levar 10 ns. A leitura de um disco rígido pode chegar a 100 MB/s, o que é quatro vezes mais lento por 
palavra de 32 bits, mas a isso têm de ser acrescentados 
5-10 ms para buscar a trilha e então esperar pelo setor 
desejado para chegar sob a cabeça de leitura. Se apenas 
uma única palavra for necessária, o acesso à memória 
será da ordem de um milhão de vezes mais rápido que 
o acesso ao disco. Como consequência dessa diferença 
em tempo de acesso, muitos sistemas de arquivos foram 
projetados com várias otimizações para melhorar o desempenho. Nesta seção cobriremos três delas. 
A técnica mais comum usada para reduzir os acessos ao disco é a cache de blocos ou cache de buffer. 
(A palavra “cache” é pronunciada como se escreve e 
é derivada do verbo francês cacher, que significa “esconder”.) Nesse contexto, uma cache é uma coleção de 
blocos que logicamente pertencem ao disco, mas estão 
sendo mantidas na memória por razões de segurança. 
Vários algoritmos podem ser usados para gerenciar 
a cache, mas um comum é conferir todas as solicitações 
para ver se o bloco necessário está na cache. Se estiver, 
o pedido de leitura pode ser satisfeito sem acesso ao 
disco. Se o bloco não estiver, primeiro ele é lido na cache e então copiado para onde quer que seja necessário. 
Solicitações subsequentes para o mesmo bloco podem 
ser satisfeitas a partir da cache. 
A operação da cache está ilustrada na Figura 4.28. 
Como há muitos (seguidamente milhares) blocos na cache, 
alguma maneira é necessária para determinar rapidamente 
se um dado bloco está presente. A maneira usual é mapear 
o dispositivo e endereço de disco e olhar o resultado em 
uma tabela de espalhamento. Todos os blocos com o mesmo valor de espalhamento são encadeados em uma lista de 
maneira que a cadeia de colisão possa ser seguida. 
Quando um bloco tem de ser carregado em uma cache cheia, alguns blocos têm de ser removidos (e reescritos para o disco se eles foram modificados depois de 
trazidos para o disco). Essa situação é muito parecida 
com a paginação, e todos os algoritmos de substituição 
de páginas usuais descritos no Capítulo 3, como FIFO, 
segunda chance e LRU, são aplicáveis. Uma diferença bem-vinda entre a paginação e a cache de blocos é 
que as referências de cache são relativamente raras, de 
maneira que é viável manter todos os blocos na ordem 
exata do LRU com listas encadeadas. 
Na Figura 4.28, vemos que além das colisões encadeadas da tabela de espalhamento, há também uma lista 
bidirecional ligando todos os blocos na ordem de uso, 
com o menos recentemente usado na frente dessa lista e 
o mais recentemente usado no fim. Quando um bloco é 
referenciado, ele pode ser removido da sua posição na 
lista bidirecional e colocado no fim. Dessa maneira, a 
ordem do LRU exata pode ser mantida. 
Infelizmente, há um problema. Agora que temos 
uma situação na qual o LRU exato é possível, ele passa 
a ser indesejável. O problema tem a ver com as quedas no sistema e consistência do sistema de arquivos discutidas na seção anterior. Se um bloco crítico, como 
um bloco do i-node, é lido na cache e modificado, mas 
não reescrito para o disco, uma queda deixará o sistema 
de arquivos em estado inconsistente. Se o bloco do i-
-node for colocado no fim da cadeia do LRU, pode levar 
algum tempo até que ele chegue à frente e seja reescrito 
para o disco. 
Além disso, alguns blocos, como blocos de i-nodes, 
raramente são referenciados duas vezes dentro de um 
intervalo curto de tempo. Essas considerações levam a 
um esquema de LRU modificado, tomando dois fatores 
em consideração:
1. É provável que o bloco seja necessário logo novamente?
2. O bloco é essencial para a consistência do sistema de arquivos? 
Para ambas as questões, os blocos podem ser divididos em categorias como blocos de i-nodes, indiretos, de 
diretórios, de dados totalmente preenchidos e de dados 
parcialmente preenchidos. Blocos que provavelmente 
não serão necessários logo de novo irão para a frente, 
em vez de para o fim da lista do LRU, de maneira que 
seus buffers serão reutilizados rapidamente. Blocos que 
talvez sejam necessários logo outra vez, como o bloco parcialmente preenchido que está sendo escrito, irão 
para o fim da lista, de maneira que permanecerão por ali 
um longo tempo. 
A segunda questão é independente da primeira. Se 
o bloco for essencial para a consistência do sistema de 
arquivos (basicamente, tudo exceto blocos de dados) e 
foi modificado, ele deve ser escrito para o disco imediatamente, não importando em qual extremidade da 
lista LRU será inserido. Ao escrever blocos críticos 
rapidamente, reduzimos muito a probabilidade de que 
uma queda arruíne o sistema de arquivos. Embora um 
usuário possa ficar descontente se um de seus arquivos 
for arruinado em uma queda, é provável que ele fique 
muito mais descontente se todo o sistema de arquivos 
for perdido. 
Mesmo com essa medida para manter intacta a integridade do sistema de arquivos, é indesejável manter 
blocos de dados na cache por tempo demais antes de 
serem escritos. Considere o drama de alguém que está 
usando um computador pessoal para escrever um livro. 
Mesmo que o nosso escritor periodicamente diga ao 
editor para escrever para o disco o arquivo que está sendo editado, há uma boa chance de que tudo ainda esteja 
na cache e nada no disco. Se o sistema cair, a estrutura 
do sistema de arquivos não será corrompida, mas um 
dia inteiro de trabalho será perdido. 
Essa situação não precisa acontecer com muita frequência para que tenhamos um usuário descontente. 
Sistemas adotam duas abordagens para lidar com isso. 
A maneira UNIX é ter uma chamada de sistema, sync, 
que força todos os blocos modificados para o disco imediatamente. Quando o sistema é inicializado, um programa, normalmente chamado update, é inicializado no 
segundo plano para adentrar um laço infinito que emite chamadas sync, dormindo por 30 s entre chamadas. 
Como consequência, não mais do que 30 s de trabalho 
são perdidos pela quebra. 
Embora o Windows tenha agora uma chamada de 
sistema equivalente a sync, chamada FlushFileBuffers, 
no passado ele não tinha. Em vez disso, ele tinha uma 
estratégia diferente que era, em alguns aspectos, melhor 
do que a abordagem do UNIX (e outros, pior). O que ele 
fazia era escrever cada bloco modificado para o disco 
tão logo ele fosse escrito para a cache. Caches nas quais 
todos os blocos modificados são escritos de volta para 
o disco imediatamente são chamadas de caches de escrita direta (write-through caches). Elas exigem mais 
E/S de disco do que caches que não são de escrita direta. 
A diferença entre essas duas abordagens pode ser 
vista quando um programa escreve um bloco totalmente preenchido de 1 KB, um caractere por vez. O UNIX 
coletará todos os caracteres na cache e escreverá o bloco uma vez a cada 30 s, ou sempre que o bloco for removido da cache. Com uma cache de escrita direta, há 
um acesso de disco para cada caractere escrito. É claro, 
a maioria dos programas trabalha com buffer interno, 
então eles normalmente não escrevem um caractere, 
mas uma linha ou unidade maior em cada chamada de 
sistema write. 
Uma consequência dessa diferença na estratégia de 
cache é que apenas remover um disco de um sistema 
UNIX sem realizar sync quase sempre resultará em dados perdidos, e frequentemente um sistema de arquivos 
corrompido também. Com as caches de escrita direta 
não há problema algum. Essas estratégias diferentes foram escolhidas porque o UNIX foi desenvolvido em um 
ambiente no qual todos os discos eram rígidos e não 
removíveis, enquanto o primeiro sistema de arquivos 
Windows foi herdado do MS-DOS, que teve seu início 
no mundo dos discos flexíveis. Como os discos rígidos 
tornaram-se a norma, a abordagem UNIX, com sua eficiência melhor (mas pior confiabilidade), tornou-se a 
norma, e também é usada agora no Windows para discos rígidos. No entanto, o NTFS toma outras medidas 
(por exemplo, journaling) para incrementar a confiabilidade, como discutido anteriormente.
Alguns sistemas operacionais integram a cache de 
buffer com a cache de páginas. Isso é especialmente 
atraente quando arquivos mapeados na memória são 
aceitos. Se um arquivo é mapeado na memória, então 
algumas das suas páginas podem estar na memória por 
causa de uma paginação por demanda. Tais páginas dificilmente são diferentes dos blocos de arquivos na cache do buffer. Nesse caso, podem ser tratadas da mesma 
maneira, com uma cache única para ambos os blocos de 
arquivos e páginas. 
Uma segunda técnica para melhorar o desempenho 
percebido do sistema de arquivos é tentar transferir 
blocos para a cache antes que eles sejam necessários 
para aumentar a taxa de acertos. Em particular, muitos 
arquivos são lidos sequencialmente. Quando se pede 
a um sistema de arquivos para obter o bloco k em um 
arquivo, ele o faz, mas quando termina, faz uma breve 
verificação na cache para ver se o bloco k + 1 já está 
ali. Se não estiver, ele programa uma leitura para o bloco k + 1 na esperança de que, quando ele for necessário, já terá chegado na cache. No mínimo, ele já estará 
a caminho. 
É claro, essa estratégia de leitura antecipada funciona apenas para arquivos que estão de fato sendo lidos 
sequencialmente. Se um arquivo estiver sendo acessado aleatoriamente, a leitura antecipada não ajuda. Na 
realidade, ela piora a situação, pois emperra a largura 
de banda do disco, fazendo leituras em blocos inúteis 
e removendo blocos potencialmente úteis da cache (e 
talvez emperrando mais ainda a largura de banda escrevendo os blocos de volta para o disco se eles estiverem 
sujos). Para ver se a leitura antecipada vale a pena ser 
feita, o sistema de arquivos pode monitorar os padrões 
de acesso para cada arquivo aberto. Por exemplo, um bit 
associado com cada arquivo pode monitorar se o arquivo está em “modo de acesso sequencial” ou “modo de 
acesso aleatório”. De início, é dado o benefício da dúvida para o arquivo e ele é colocado no modo de acesso 
sequencial. No entanto, sempre que uma busca é feita, 
o bit é removido. Se as leituras sequenciais começarem 
de novo, o bit é colocado em 1 novamente. Dessa maneira, o sistema de arquivos pode formular um palpite 
razoável sobre se ele deve ler antecipadamente ou não. 
Se ele cometer algum erro de vez em quando, não é um 
desastre, apenas um pequeno desperdício de largura de 
banda de disco. A cache e a leitura antecipada não são as únicas 
maneiras de incrementar o desempenho do sistema de 
arquivos. Outra técnica importante é reduzir o montante de movimento do braço do disco colocando blocos 
que têm mais chance de serem acessados em sequência próximos uns dos outros, de preferência no mesmo 
cilindro. Quando um arquivo de saída é escrito, o sistema de arquivos tem de alocar os blocos um de cada 
vez, conforme a demanda. Se os blocos livres forem 
registrados em um mapa de bits, e todo o mapa de bits 
estiver na memória principal, será bastante fácil escolher um bloco livre o mais próximo possível do bloco 
anterior. Com uma lista de blocos livres, na qual uma 
parte está no disco, é muito mais difícil alocar blocos 
próximos juntos. 
No entanto, mesmo com uma lista de blocos livres, 
algum agrupamento de blocos pode ser conseguido. O 
truque é monitorar o armazenamento do disco, não em 
blocos, mas em grupos de blocos consecutivos. Se todos 
os setores consistirem em 512 bytes, o sistema poderia 
usar blocos de 1 KB (2 setores), mas alocar o armazenamento de disco em unidades de 2 blocos (4 setores). 
Isso não é o mesmo que ter blocos de disco de 2 KB, já 
que a cache ainda usaria blocos de 1 KB e as transferências de disco ainda seriam de 1 KB, mas a leitura de 
um arquivo sequencialmente em um sistema de outra 
maneira ocioso reduziria o número de buscas por um 
fator de dois, melhorando consideravelmente o desempenho. Uma variação sobre o mesmo tema é levar em 
consideração o posicionamento rotacional. Quando aloca blocos, o sistema faz uma tentativa de colocar blocos 
consecutivos em um arquivo no mesmo cilindro. 
Outro gargalo de desempenho em sistemas que usam 
i-nodes (ou qualquer equivalente a eles) é que a leitura 
mesmo de um arquivo curto exige dois acessos de disco: um para o i-node e outro para o bloco. A localização 
usual do i-node é mostrada da Figura 4.29(a). Aqui todos os i-nodes estão próximos do início do disco, então 
a distância média entre um i-node e seus blocos será 
metade do número de cilindros, exigindo longas buscas. 
Uma melhora simples de desempenho é colocar os 
i-nodes no meio do disco, em vez de no início, reduzindo assim a busca média entre o i-node e o primeiro bloco por um fator de dois. Outra ideia, mostrada 
na Figura 4.29(b), é dividir o disco em grupos de cilindros, cada um com seus próprios i-nodes, blocos 
e lista de livres (MCKUSICK et al., 1984). Ao criar 
um arquivo novo, qualquer i-node pode ser escolhido, 
mas uma tentativa é feita para encontrar um bloco no mesmo grupo de cilindros que o i-node. Se nenhum 
estiver disponível, então um bloco em um grupo de cilindros próximo é usado. 
É claro, o movimento do braço do disco e o tempo de rotação são relevantes somente se o disco os 
tem. Mais e mais computadores vêm equipados com 
discos de estado sólido (SSDs — Solid State Disks) 
que não têm parte móvel alguma. Para esses discos, 
construídos com a mesma tecnologia dos flash cards, 
acessos aleatórios são tão rápidos quanto os sequenciais e muitos dos problemas dos discos tradicionais 
deixam de existir. Infelizmente, surgem novos problemas. Por exemplo, SSDs têm propriedades peculiares 
em suas operações de leitura, escrita e remoção. Em 
particular, cada bloco pode ser escrito apenas um número limitado de vezes, portanto um grande cuidado 
é tomado para dispersar uniformemente o desgaste 
sobre o disco.
Quando o sistema operacional é inicialmente instalado, os programas e os arquivos que ele precisa são instalados de modo consecutivo começando no início do 
disco, cada um seguindo diretamente o anterior. Todo o 
espaço de disco livre está em uma única unidade contígua seguindo os arquivos instalados. No entanto, à medida que o tempo passa, arquivos são criados e removidos, 
e o disco prejudica-se com a fragmentação, com arquivos e espaços vazios por toda parte. Em consequência, 
quando um novo arquivo é criado, os blocos usados para 
isso podem estar espalhados por todo o disco, resultando 
em um desempenho ruim. 
O desempenho pode ser restaurado movendo os arquivos a fim de deixá-los contíguos e colocando todo 
(ou pelo menos a maior parte) o espaço livre em uma
ou mais regiões contíguas no disco. O Windows tem um 
programa, defrag, que faz precisamente isso. Os usuários do Windows devem executá-lo com regularidade, 
exceto em SSDs. 
A desfragmentação funciona melhor em sistemas de 
arquivos que têm bastante espaço livre em uma região 
contígua ao fim da partição. Esse espaço permite que o 
programa de desfragmentação selecione arquivos fragmentados próximos do início da partição e copie todos 
os seus blocos para o espaço livre. Fazê-lo libera um 
bloco contíguo de espaço próximo do início da partição 
na qual o original ou outros arquivos podem ser colocados contiguamente. O processo pode então ser repetido 
com o próximo pedaço de espaço de disco etc. 
Alguns arquivos não podem ser movidos, incluindo 
o arquivo de paginação, o arquivo de hibernação e o log 
de journaling, pois a administração que seria necessária 
para fazê-lo daria mais trabalho do que seu valor. Em 
alguns sistemas, essas áreas são contíguas e de tamanho 
fixo de qualquer maneira, então elas não precisam ser 
desfragmentadas. O único momento em que sua falta de 
mobilidade é um problema é quando elas estão localizadas próximas do fim da partição e o usuário quer reduzir 
o tamanho da partição. A única maneira de solucionar 
esse problema é removê-las completamente, redimensionar a partição e então recriá-las depois. 
Os sistemas de arquivos Linux (especialmente ext2 e 
ext3) geralmente sofrem menos com a desfragmentação 
do que os sistemas Windows pela maneira que os blocos de discos são selecionados, então a desfragmentação manual raramente é exigida. Também, os SSDs não 
sofrem de maneira alguma com a fragmentação. Na realidade, desfragmentar um SSD é contraprodutivo. Não 
apenas não há ganho em desempenho, como os SSDs se 
desgastam; portanto, desfragmentá-los apenas encurta 
sua vida.
